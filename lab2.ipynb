{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leSIMPus/lab1-algorithms/blob/main/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №2 Парсинг"
      ],
      "metadata": {
        "id": "kHV7Tz-MHjNG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Теоретический материал к Лабораторной работе №2**\n",
        "\n",
        "**Тема: Основы автоматизированного сбора данных из веб-источников**\n",
        "\n",
        "#### **Введение: от веб-страницы к структурированным данным**\n",
        "\n",
        "Современный Интернет представляет собой крупнейший в истории человечества источник информации. Однако эти данные, как правило, представлены в неструктурированном, человекочитаемом формате — в виде веб-страниц. Процесс автоматического извлечения данных с веб-сайтов и их преобразования в структурированный, машиночитаемый вид (например, в таблицу или базу данных) получил название **веб-парсинг** (от англ. *to parse* — анализировать, разбирать) или **веб-скрейпинг** (*to scrape* — соскребать).\n",
        "\n",
        "Для выполнения этой задачи мы будем использовать экосистему из нескольких специализированных библиотек Python, каждая из которых выполняет свою строго определенную функцию. В данной работе мы сосредоточимся на двух основных инструментах для работы со статичными сайтами.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Библиотека `requests`: Протокол взаимодействия с веб-сервером**\n",
        "\n",
        "Любое взаимодействие в сети Интернет начинается с отправки запроса. Когда вы вводите адрес сайта в браузере, он отправляет HTTP-запрос к серверу, на котором этот сайт расположен. Сервер в ответ присылает HTML-документ, который браузер и отображает.\n",
        "\n",
        "Библиотека `requests` является отраслевым стандартом в Python для выполнения этой задачи программным путем. Её основная функция — абстрагироваться от сложностей сетевых протоколов и предоставить простой интерфейс для отправки HTTP-запросов.\n",
        "\n",
        "**Ключевые концепции и синтаксис:**\n",
        "\n",
        "1.  **Отправка GET-запроса:** Основной метод, который мы используем, — `requests.get()`. Он эмулирует переход по URL-адресу в браузере.\n",
        "\n",
        "    ```python\n",
        "    import requests\n",
        "\n",
        "    # URL-адрес целевого ресурса\n",
        "    url = 'http://quotes.toscrape.com/'\n",
        "\n",
        "    # Отправка запроса. Вся информация об ответе сервера будет храниться в объекте 'response'\n",
        "    response = requests.get(url)\n",
        "    ```\n",
        "\n",
        "2.  **Объект ответа (`response`):** Результатом вызова `requests.get()` является объект, содержащий всю информацию об ответе сервера. Наиболее важные для нас атрибуты:\n",
        "    *   `response.status_code`: Числовой код состояния HTTP. Успешный запрос возвращает код **200**. Коды, начинающиеся с 4 (например, 404 Not Found) или 5 (например, 500 Internal Server Error), свидетельствуют об ошибках. Проверка этого кода — обязательный шаг для написания надежного парсера.\n",
        "    *   `response.text`: Содержимое ответа сервера в виде текстовой строки. В нашем случае это будет полный HTML-код запрошенной страницы.\n",
        "\n",
        "    **Пример использования:**\n",
        "\n",
        "    ```python\n",
        "    if response.status_code == 200:\n",
        "        print(\"Запрос выполнен успешно.\")\n",
        "        # Получаем HTML-код страницы\n",
        "        html_content = response.text\n",
        "        print(\"Длина полученного HTML-документа:\", len(html_content), \"символов.\")\n",
        "    else:\n",
        "        print(\"Произошла ошибка при запросе. Код:\", response.status_code)\n",
        "    ```\n",
        "\n",
        "На данном этапе `requests` свою задачу выполнил: мы получили \"сырой\" HTML-документ. Далее его необходимо проанализировать.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Библиотека `BeautifulSoup`: Навигация по DOM-структуре документа**\n",
        "\n",
        "HTML-документ — это не просто текст, а строго иерархическая структура, описываемая с помощью тегов. Эту структуру принято называть **DOM-деревом** (Document Object Model). Библиотека `BeautifulSoup` является мощнейшим инструментом для парсинга этого дерева. Она преобразует текстовую строку HTML в объектную модель, по которой можно осуществлять удобную навигацию и поиск.\n",
        "\n",
        "**Ключевые концепции и синтаксис:**\n",
        "\n",
        "1.  **Инициализация объекта (\"создание супа\"):** Первым шагом является создание экземпляра класса `BeautifulSoup`, который принимает на вход HTML-текст и название парсера.\n",
        "\n",
        "    ```python\n",
        "    from bs4 import BeautifulSoup\n",
        "\n",
        "    # html_content - это строка, полученная от requests.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    ```\n",
        "\n",
        "2.  **Поиск элементов:** `BeautifulSoup` предоставляет два основных метода для поиска тегов внутри DOM-дерева. Они используют **селекторы** — комбинации имени тега и его атрибутов (например, `class` или `id`).\n",
        "\n",
        "    *   **`soup.find(tag, attributes)`**: Ищет **первый** элемент, соответствующий заданным критериям, и возвращает его как объект тега. Если ничего не найдено, возвращает `None`.\n",
        "\n",
        "      **Синтаксис:**\n",
        "      ```python\n",
        "      # Поиск первого тега <h1>\n",
        "      first_h1 = soup.find('h1')\n",
        "\n",
        "      # Поиск первого тега <span> с атрибутом class='text'\n",
        "      # ВАЖНО: 'class' - зарезервированное слово в Python, поэтому используется аргумент 'class_'\n",
        "      first_quote_text = soup.find('span', class_='text')\n",
        "      ```\n",
        "\n",
        "    *   **`soup.find_all(tag, attributes)`**: Ищет **все** элементы, соответствующие критериям, и возвращает их в виде списка (`list`). Если ничего не найдено, возвращает пустой список.\n",
        "\n",
        "      **Синтаксис:**\n",
        "      ```python\n",
        "      # Поиск всех тегов <div> с атрибутом class='quote'\n",
        "      all_quote_containers = soup.find_all('div', class_='quote')\n",
        "\n",
        "      # Итерация по результатам\n",
        "      for container in all_quote_containers:\n",
        "          # Внутри каждого найденного контейнера можно продолжать поиск\n",
        "          author = container.find('small', class_='author')\n",
        "          print(author.text)\n",
        "      ```\n",
        "\n",
        "3.  **Извлечение содержимого из найденных тегов:** После того как тег найден, из него можно извлечь полезную информацию.\n",
        "    *   **`.text`**: Возвращает все текстовое содержимое внутри тега и его дочерних элементов в виде одной строки.\n",
        "    *   **`tag['attribute_name']`**: Позволяет получить значение конкретного атрибута тега. Чаще всего используется для извлечения ссылок из атрибута `href` у тега `<a>`.\n",
        "\n",
        "      **Пример использования:**\n",
        "      ```python\n",
        "      # Найдем тег с цитатой\n",
        "      quote_element = soup.find('div', class_='quote')\n",
        "\n",
        "      # Извлекаем текст цитаты\n",
        "      text = quote_element.find('span', class_='text').text\n",
        "      print(\"Текст цитаты:\", text)\n",
        "\n",
        "      # Извлекаем ссылку на автора (если она есть)\n",
        "      author_link = quote_element.find('a') # Находим первый тег <a> внутри контейнера\n",
        "      if author_link:\n",
        "          href_value = author_link['href']\n",
        "          print(\"Ссылка на страницу автора:\", href_value)\n",
        "      ```\n",
        "\n",
        "\n",
        "\n",
        "Рассмотренный ранее подход с использованием библиотек `requests` и `BeautifulSoup` является высокоэффективным для работы со **статичными** веб-страницами. \"Статичная\" страница — это документ, HTML-код которого полностью формируется на сервере и доставляется клиенту в готовом виде. Однако значительная часть современного веба функционирует иначе.\n",
        "\n",
        "**Динамические веб-сайты** активно используют технологию JavaScript для модификации своего содержимого непосредственно в браузере пользователя *после* первоначальной загрузки страницы. Это может быть подгрузка новостной ленты при прокрутке, отображение цен на авиабилеты после выбора маршрута, обновление графика погоды в реальном времени.\n",
        "\n",
        "При попытке парсинга таких сайтов с помощью `requests`, мы получим лишь базовый HTML-шаблон, в котором искомые данные будут отсутствовать, поскольку JavaScript-код, ответственный за их загрузку и отображение, не будет исполнен.\n",
        "\n",
        "Для решения этой фундаментальной проблемы необходим инструмент, который не просто запрашивает HTML, а эмулирует поведение полноценного веб-браузера. Таким инструментом является библиотека **Selenium**.\n",
        "\n",
        "---\n",
        "\n",
        "#### **1. Парадигма Selenium: Управление браузером вместо отправки запросов**\n",
        "\n",
        "Основное отличие Selenium от `requests` заключается в подходе. Если `requests` — это \"курьер\", доставляющий HTML-документ, то **Selenium — это \"робот-пользователь\"**, который программно запускает и управляет реальным браузером (Google Chrome, Firefox и др.).\n",
        "\n",
        "Этот подход позволяет:\n",
        "*   **Исполнять JavaScript:** Браузер под управлением Selenium загружает и выполняет все скрипты на странице.\n",
        "*   **Взаимодействовать с элементами:** Selenium может эмулировать действия пользователя, такие как клики по кнопкам, ввод текста в поля, прокрутку страницы.\n",
        "*   **Работать с итоговым HTML:** После всех динамических модификаций мы получаем доступ к финальному, \"отрисованному\" DOM-дереву, которое и видит пользователь.\n",
        "\n",
        "---\n",
        "\n",
        "#### **2. Ключевые компоненты и синтаксис Selenium**\n",
        "\n",
        "##### **2.1. WebDriver: Мост между кодом и браузером**\n",
        "\n",
        "Центральным элементом Selenium является **WebDriver**. Это программный интерфейс (API), который выступает в роли \"драйвера\" или \"переводчика\" между командами в вашем Python-скрипте и действиями в реальном приложении браузера.\n",
        "\n",
        "**Инициализация WebDriver:**\n",
        "Для начала работы необходимо создать экземпляр WebDriver для конкретного браузера. Современные версии Selenium (`4.6.0` и новее) автоматически управляют загрузкой необходимого драйвера.\n",
        "\n",
        "```python\n",
        "from selenium import webdriver\n",
        "\n",
        "# Инициализация драйвера для Google Chrome.\n",
        "# Selenium сам скачает и настроит chromedriver.\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# Команда ниже откроет окно браузера Chrome\n",
        "```\n",
        "\n",
        "##### **2.2. Навигация и получение страницы**\n",
        "Основной метод для загрузки страницы — `driver.get(url)`.\n",
        "\n",
        "```python\n",
        "url = 'https://www.gismeteo.ru/weather-moscow-4368/'\n",
        "driver.get(url) # Браузер откроется и перейдет по указанному адресу\n",
        "```\n",
        "\n",
        "##### **2.3. Проблема асинхронности и механизмы ожидания**\n",
        "\n",
        "Это **самая важная и сложная концепция** при работе с Selenium. Ваш Python-скрипт выполняется гораздо быстрее, чем браузер успевает загрузить страницу и выполнить все JavaScript-команды. Если вы попытаетесь найти элемент сразу после вызова `driver.get()`, скорее всего, вы получите ошибку `NoSuchElementException`, потому что элемент еще не появился на странице.\n",
        "\n",
        "**Неправильный подход:** `time.sleep(5)`. Использование жестких пауз — плохая практика. Пауза может быть слишком короткой (данные не успеют загрузиться) или слишком длинной (скрипт будет работать неэффективно).\n",
        "\n",
        "**Правильный подход: Явные ожидания (Explicit Waits)**\n",
        "Это механизм, который заставляет WebDriver ждать наступления определенного события (например, появления элемента) в течение заданного максимального времени.\n",
        "\n",
        "**Синтаксис:**\n",
        "```python\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "\n",
        "# Создаем объект ожидания: ждать максимум 10 секунд\n",
        "wait = WebDriverWait(driver, 10)\n",
        "\n",
        "# Команда \"ждать, пока элемент с указанным локатором не станет присутствовать в DOM\"\n",
        "# By.CLASS_NAME — это способ поиска (локатор)\n",
        "# 'unit_temperature_c' — значение локатора\n",
        "temperature_element = wait.until(\n",
        "    EC.presence_of_element_located((By.CLASS_NAME, 'unit_temperature_c'))\n",
        ")\n",
        "```\n",
        "\n",
        "##### **2.4. Поиск элементов и взаимодействие с ними**\n",
        "\n",
        "Для поиска элементов Selenium использует **локаторы**, которые указывают, *как* именно искать элемент. Они импортируются из `selenium.webdriver.common.by.By`.\n",
        "\n",
        "Основные локаторы:\n",
        "*   `By.ID`\n",
        "*   `By.CLASS_NAME`\n",
        "*   `By.TAG_NAME`\n",
        "*   `By.XPATH` (самый мощный и сложный)\n",
        "*   `By.CSS_SELECTOR` (часто самый удобный)\n",
        "\n",
        "**Методы поиска:**\n",
        "*   `driver.find_element(By.ЛОКАТОР, 'значение')`: Ищет **первый** элемент.\n",
        "*   `driver.find_elements(By.ЛОКАТОР, 'значение')`: Ищет **все** элементы и возвращает список.\n",
        "\n",
        "**Методы взаимодействия:**\n",
        "*   `.click()`: Кликнуть по элементу.\n",
        "*   `.send_keys('текст')`: Ввести текст в поле ввода.\n",
        "*   `.text`: Получить видимый текст элемента.\n",
        "*   `.get_attribute('атрибут')`: Получить значение атрибута (например, `href`).\n",
        "\n",
        "**Пример:**\n",
        "```python\n",
        "# Найти поле поиска по его ID\n",
        "search_box = driver.find_element(By.ID, 'search-input')\n",
        "\n",
        "# Ввести текст в поле\n",
        "search_box.send_keys('Погода в Санкт-Петербурге')\n",
        "\n",
        "# Найти и кликнуть по кнопке поиска\n",
        "search_button = driver.find_element(By.CLASS_NAME, 'search-button')\n",
        "search_button.click()\n",
        "```\n",
        "\n",
        "##### **2.5. Интеграция с BeautifulSoup и завершение работы**\n",
        "\n",
        "После того как Selenium выполнил все необходимые действия (клики, прокрутку) и дождался появления данных, мы можем получить итоговый HTML-код страницы.\n",
        "\n",
        "*   `driver.page_source`: Атрибут, содержащий финальный HTML-код страницы в виде строки.\n",
        "\n",
        "Этот код можно передать в `BeautifulSoup` для более удобного и быстрого парсинга, комбинируя сильные стороны обеих библиотек.\n",
        "\n",
        "**Обязательный шаг: Завершение сессии**\n",
        "После окончания работы необходимо закрыть браузер и завершить сессию WebDriver, чтобы освободить системные ресурсы.\n",
        "\n",
        "*   `driver.quit()`: Закрывает все окна браузера и завершает процесс WebDriver.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K4E9fULxHozb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Requests"
      ],
      "metadata": {
        "id": "VuF-Ty7YmGCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json # Библиотека для работы с JSON\n",
        "\n",
        "# --- ШАГ 1: Определение цели ---\n",
        "# URL API для получения репозиториев пользователя.\n",
        "# Обратите внимание, что это не обычный URL для браузера!\n",
        "api_base_url = \"https://api.github.com/users/\"\n",
        "username = \"gvanrossum\"\n",
        "full_api_url = f\"{api_base_url}{username}/repos\"\n",
        "\n",
        "# --- ШАГ 2: Использование параметров запроса (params) ---\n",
        "# API позволяет настраивать вывод. Мы хотим отсортировать репозитории\n",
        "# по дате создания ('created') и получать по 10 штук за раз.\n",
        "# Для этого используются GET-параметры, которые requests умеет добавлять к URL.\n",
        "\n",
        "# --- ЗАДАНИЕ ---\n",
        "# Создайте словарь 'params', который будет содержать следующие GET-параметры:\n",
        "# 1. 'sort': со значением 'created' (сортировка по дате создания)\n",
        "# 2. 'per_page': со значением '10' (выводить по 10 репозиториев на странице)\n",
        "# ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "params = {\n",
        "    '???': 'created',\n",
        "    '???': '10'\n",
        "}\n",
        "# ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "\n",
        "# --- ШАГ 3: Выполнение запроса и обработка JSON ---\n",
        "print(f\"Отправляю запрос на: {full_api_url}\")\n",
        "response = requests.get(full_api_url, params=params)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    print(\"Запрос успешен!\")\n",
        "    # --- ЗАДАНИЕ ---\n",
        "    # Ответ от API приходит в формате JSON.\n",
        "    # У объекта response есть специальный метод .json(), который\n",
        "    # автоматически преобразует этот ответ в python-объект (список словарей).\n",
        "    # Используйте его и сохраните результат в переменную 'repos_data'.\n",
        "    # ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "    repos_data = response.json()\n",
        "    # ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "    # --- ШАГ 4: Вывод результатов ---\n",
        "    print(f\"Последние 10 созданных репозиториев пользователя {username}:\")\n",
        "    # Пройдемся циклом по списку репозиториев и выведем их названия и URL\n",
        "    for repo in repos_data:\n",
        "        print(f\"  - Название: {repo['name']}, URL: {repo['html_url']}\")\n",
        "\n",
        "else:\n",
        "    print(f\"Ошибка! Статус-код: {response.status_code}\")\n",
        "    print(f\"Сообщение: {response.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUxZBQrWLKEi",
        "outputId": "680e55b4-c400-40e2-9368-ea688de25536"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отправляю запрос на: https://api.github.com/users/gvanrossum/repos\n",
            "Запрос успешен!\n",
            "Последние 10 созданных репозиториев пользователя gvanrossum:\n",
            "  - Название: 500lines, URL: https://github.com/gvanrossum/500lines\n",
            "  - Название: asyncio, URL: https://github.com/gvanrossum/asyncio\n",
            "  - Название: ballot-box, URL: https://github.com/gvanrossum/ballot-box\n",
            "  - Название: c-parser, URL: https://github.com/gvanrossum/c-parser\n",
            "  - Название: cpython, URL: https://github.com/gvanrossum/cpython\n",
            "  - Название: ctok, URL: https://github.com/gvanrossum/ctok\n",
            "  - Название: devguide, URL: https://github.com/gvanrossum/devguide\n",
            "  - Название: exceptiongroup, URL: https://github.com/gvanrossum/exceptiongroup\n",
            "  - Название: guidos_time_machine, URL: https://github.com/gvanrossum/guidos_time_machine\n",
            "  - Название: gvanrossum.github.io, URL: https://github.com/gvanrossum/gvanrossum.github.io\n",
            "  - Название: http-get-perf, URL: https://github.com/gvanrossum/http-get-perf\n",
            "  - Название: minithesis, URL: https://github.com/gvanrossum/minithesis\n",
            "  - Название: mirror-cwi-stdwin, URL: https://github.com/gvanrossum/mirror-cwi-stdwin\n",
            "  - Название: mypy, URL: https://github.com/gvanrossum/mypy\n",
            "  - Название: mypy-dummy, URL: https://github.com/gvanrossum/mypy-dummy\n",
            "  - Название: old-demos, URL: https://github.com/gvanrossum/old-demos\n",
            "  - Название: path-pep, URL: https://github.com/gvanrossum/path-pep\n",
            "  - Название: patma, URL: https://github.com/gvanrossum/patma\n",
            "  - Название: pep550, URL: https://github.com/gvanrossum/pep550\n",
            "  - Название: peps, URL: https://github.com/gvanrossum/peps\n",
            "  - Название: Pyjion, URL: https://github.com/gvanrossum/Pyjion\n",
            "  - Название: pythonlabs, URL: https://github.com/gvanrossum/pythonlabs\n",
            "  - Название: pythonlabs-com-azure, URL: https://github.com/gvanrossum/pythonlabs-com-azure\n",
            "  - Название: pytype, URL: https://github.com/gvanrossum/pytype\n",
            "  - Название: pyxl3, URL: https://github.com/gvanrossum/pyxl3\n",
            "  - Название: TypeChat, URL: https://github.com/gvanrossum/TypeChat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from IPython.display import Image # Для отображения картинки в Colab\n",
        "\n",
        "# --- ШАГ 1: Найти URL изображения ---\n",
        "# Сначала нам нужно, как в прошлой лабораторной, найти ссылку на логотип.\n",
        "base_url = 'https://vk.com/'\n",
        "response = requests.get(base_url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Логотип находится в теге <img> внутри тега <a> с href=\"/\".\n",
        "# --- ЗАДАНИЕ ---\n",
        "# Найдите тег 'img' и извлеките из него значение атрибута 'src'.\n",
        "# Сохраните относительный URL в переменную 'relative_logo_url'.\n",
        "# ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "logo_element = soup.find('a', href='/').find('img')\n",
        "relative_logo_url = logo_element['src']\n",
        "# ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "# --- ШАГ 2: Преобразование относительного URL в абсолютный ---\n",
        "# Ссылка в 'src' относительная ('/images/logo.png').\n",
        "# Чтобы ее скачать, нужен полный URL.\n",
        "absolute_logo_url = urljoin(base_url, relative_logo_url)\n",
        "print(f\"Найден абсолютный URL логотипа: {absolute_logo_url}\")\n",
        "\n",
        "\n",
        "# --- ШАГ 3: Скачивание бинарного контента ---\n",
        "print(\"Скачиваю изображение...\")\n",
        "# --- ЗАДАНИЕ ---\n",
        "# Отправьте GET-запрос на 'absolute_logo_url'.\n",
        "# Ответ для бинарных файлов нужно получать через атрибут .content, а не .text\n",
        "# Сохраните результат в переменную 'image_content'.\n",
        "# ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "image_response = requests.get(absolute_logo_url)\n",
        "if image_response.status_code == 200:\n",
        "    image_content = image_response.content\n",
        "    print(\"Изображение успешно скачано!\")\n",
        "# ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "    # --- ШАГ 4: Сохранение файла на диск ---\n",
        "    # Используем стандартный синтаксис Python для записи файлов.\n",
        "    # 'wb' означает \"write binary\" - запись в бинарном режиме.\n",
        "    file_name = 'logo.png'\n",
        "    # --- ЗАДАНИЕ ---\n",
        "    # Откройте файл 'file_name' для записи в бинарном режиме ('wb')\n",
        "    # и запишите в него 'image_content'.\n",
        "    # ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "    with open(file_name, 'wb') as f:\n",
        "        f.write(image_content)\n",
        "    # ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "    print(f\"Файл '{file_name}' сохранен в текущую директорию Colab.\")\n",
        "\n",
        "    # Отобразим скачанное изображение прямо в блокноте\n",
        "    display(Image(file_name))\n",
        "else:\n",
        "    print(f\"Ошибка при скачивании изображения! Статус-код: {image_response.status_code}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "jGRj_FXxLMwq",
        "outputId": "b9e9aa00-ee4e-44b0-a9ab-dfba15080494"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найден абсолютный URL логотипа: https://vk.com/images/mobile/icons/vk_logo_color_32.png\n",
            "Скачиваю изображение...\n",
            "Изображение успешно скачано!\n",
            "Файл 'logo.png' сохранен в текущую директорию Colab.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAMAAABEpIrGAAAABGdBTUEAALGPC/xhBQAAAAFzUkdCAK7OHOkAAAByUExURUdwTAB3/wB3/wB0/wB2/wB3/wB2/wB3/wB1/wB1/wB2/wB3/wB1/////wB3/4C7/xB//7/d/yCI/6DM/9/u/2Cq/8/l/3Cy/+/3/zCR/3+7/+/2/0CZ/6/V/5DD/1+q/4/E/4/D/1Ch/5/M/8/m/3Cz/03vr7cAAAANdFJOUwDvr6Cfb3Ag37/Pz7C481VfAAABBklEQVQ4y42T7XbCIAyG00ol6IKUtbr5MXXT+79FCbQUOad07w/gwEN4IQHASTZii6gTVajqRkKQVHpGwiMS9ayQiZUuSLkAuigJ6zKwhroMCFBlYAtYBhCqJcB3n0TkB67fcd8StYGYAJMAdgRHYOcmvhOAN9gU6N3EYQKOU4ABMDScySvm7tq9fgPY1MkEoPvidZMBbOIWAKJ4gwQwvO0aAfrLI+gDTx8Z2Lc87GwG+JtR5+3bR3JKBMxliM73u+QPFY0OC2zpFGyk2bQ/3bjzOb5claXbnH/9k5u+788hm5tyulW5qLX+WC7axbIvV634z9cDOetTxf/d1ArfyhtxI8L3fwFvQzXbYV578gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# --- ШАГ 1: Создание сессии и получение CSRF-токена ---\n",
        "# requests.Session() - это объект, который будет \"помнить\" cookies между запросами.\n",
        "# --- ЗАДАНИЕ ---\n",
        "# Создайте объект сессии и сохраните его в переменную 'session'.\n",
        "# ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "session = requests.Session()\n",
        "# ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "login_url = 'http://quotes.toscrape.com/login'\n",
        "\n",
        "# Сначала делаем GET-запрос, чтобы получить страницу входа и специальный\n",
        "# \"csrf_token\" - это защита от межсайтовой подделки запроса.\n",
        "response_login_page = session.get(login_url)\n",
        "soup_login = BeautifulSoup(response_login_page.text, 'html.parser')\n",
        "\n",
        "# --- ЗАДАНИЕ ---\n",
        "# Найдите тег 'input' у которого атрибут name равен 'csrf_token'\n",
        "# и извлеките из него значение атрибута 'value'.\n",
        "# ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "csrf_token = soup_login.find('input', {'name': 'csrf_token'})['value']\n",
        "# ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "print(f\"Получен CSRF токен: {csrf_token}\")\n",
        "\n",
        "\n",
        "# --- ШАГ 2: Подготовка данных для POST-запроса ---\n",
        "# Это данные, которые мы бы ввели в форму на сайте.\n",
        "# Имена полей ('username', 'password') нужно посмотреть в HTML-коде страницы.\n",
        "payload = {\n",
        "    'csrf_token': csrf_token,\n",
        "    'username': 'admin',  # Используем стандартные учетные данные для этого сайта\n",
        "    'password': 'admin'\n",
        "}\n",
        "\n",
        "\n",
        "# --- ШАГ 3: Отправка POST-запроса для аутентификации ---\n",
        "# Мы отправляем POST-запрос на тот же URL, но уже с нашими данными.\n",
        "# Сессия автоматически сохранит cookies, которые вернет сервер после успешного входа.\n",
        "# --- ЗАДАНИЕ ---\n",
        "# Отправьте POST-запрос с помощью объекта 'session'.\n",
        "# URL: login_url\n",
        "# Данные: payload\n",
        "# Сохраните ответ в 'response_post'.\n",
        "# ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "response_post = session.post(login_url, data=payload)\n",
        "# ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "\n",
        "# --- ШАГ 4: Доступ к защищенной странице ---\n",
        "# Теперь, используя ту же сессию, мы можем зайти на любую страницу сайта,\n",
        "# и сервер будет \"видеть\" нас как залогиненного пользователя.\n",
        "print(\"\\nПробую получить доступ к главной странице после логина...\")\n",
        "response_main_page = session.get('http://quotes.toscrape.com/')\n",
        "soup_main = BeautifulSoup(response_main_page.text, 'html.parser')\n",
        "\n",
        "# Проверим, видим ли мы кнопку \"Logout\"\n",
        "logout_button = soup_main.find('a', href='/logout')\n",
        "\n",
        "if logout_button:\n",
        "    print(\"Успех! Мы авторизованы. Сервер видит кнопку 'Logout'.\")\n",
        "    print(logout_button.text)\n",
        "else:\n",
        "    print(\"Неудача. Авторизация не удалась, кнопка 'Logout' не найдена.\")"
      ],
      "metadata": {
        "id": "U80X12wQLOwz",
        "outputId": "69135f84-2b2f-41a4-bd69-2a9f224a0953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Получен CSRF токен: RsXbLJwHSlVrvpkAxmyEfDFtQgcUnIMqBuGPOZjYCiaNehoKWdTz\n",
            "\n",
            "Пробую получить доступ к главной странице после логина...\n",
            "Успех! Мы авторизованы. Сервер видит кнопку 'Logout'.\n",
            "Logout\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NjoG6qGmmJkG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BeautifulSoup4"
      ],
      "metadata": {
        "id": "a2FxGZ6QmLdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# --- ШАГ 1: Получение HTML ---\n",
        "url = 'http://books.toscrape.com/'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# --- ШАГ 2: Поиск общего контейнера ---\n",
        "# Все книги находятся внутри элементов <article> с классом 'product_pod'.\n",
        "# --- ЗАДАНИЕ ---\n",
        "# Найдите ВСЕ такие контейнеры с помощью .find_all() и сохраните в 'all_books'.\n",
        "# ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "all_books = soup.find_all('article', class_='product_pod')\n",
        "# ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "print(f\"Найдено книг на странице: {len(all_books)}\")\n",
        "books_data = []\n",
        "\n",
        "# --- ШАГ 3: Извлечение данных в цикле ---\n",
        "for book in all_books:\n",
        "    # --- ЗАДАНИЕ A: Найти название книги ---\n",
        "    # Название находится в теге <a> внутри тега <h3>.\n",
        "    # Нужно извлечь его атрибут 'title'.\n",
        "    # ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "    title = book.find('h3').find('a')['title']\n",
        "    # ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "    # --- ЗАДАНИЕ B: Найти цену ---\n",
        "    # Цена находится в теге <p> с классом 'price_color'.\n",
        "    # ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "    price = book.find('p', class_='price_color').text\n",
        "    # ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "    # --- ЗАДАНИЕ C: Найти рейтинг ---\n",
        "    # Рейтинг находится в атрибуте 'class' у тега <p>, который начинается с 'star-rating'.\n",
        "    # Например: <p class=\"star-rating Three\">. Нам нужно извлечь слово 'Three'.\n",
        "    # ▼▼▼ ВАШ КОД ЗДЕСЬ ▼▼▼\n",
        "    rating_container = book.find('p', class_='star-rating')\n",
        "    # Атрибут 'class' возвращает список классов, например, ['star-rating', 'Three']\n",
        "    rating = rating_container['class'][1] # Берем второй элемент\n",
        "    # ▲▲▲ ВАШ КОД ЗДЕСЬ ▲▲▲\n",
        "\n",
        "    # Добавляем собранные данные в наш список\n",
        "    books_data.append({\n",
        "        'Title': title,\n",
        "        'Price': price,\n",
        "        'Rating': rating\n",
        "    })\n",
        "\n",
        "# --- ШАГ 4: Вывод результата ---\n",
        "df = pd.DataFrame(books_data)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "BBNhpZgPMGUv",
        "outputId": "b9037dfe-5ca5-4542-b5d8-ad729865c94e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено книг на странице: 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                Title    Price Rating\n",
              "0                                A Light in the Attic  Â£51.77  Three\n",
              "1                                  Tipping the Velvet  Â£53.74    One\n",
              "2                                          Soumission  Â£50.10    One\n",
              "3                                       Sharp Objects  Â£47.82   Four\n",
              "4               Sapiens: A Brief History of Humankind  Â£54.23   Five\n",
              "5                                     The Requiem Red  Â£22.65    One\n",
              "6   The Dirty Little Secrets of Getting Your Dream...  Â£33.34   Four\n",
              "7   The Coming Woman: A Novel Based on the Life of...  Â£17.93  Three\n",
              "8   The Boys in the Boat: Nine Americans and Their...  Â£22.60   Four\n",
              "9                                     The Black Maria  Â£52.15    One\n",
              "10     Starving Hearts (Triangular Trade Trilogy, #1)  Â£13.99    Two\n",
              "11                              Shakespeare's Sonnets  Â£20.66   Four\n",
              "12                                        Set Me Free  Â£17.46   Five\n",
              "13  Scott Pilgrim's Precious Little Life (Scott Pi...  Â£52.29   Five\n",
              "14                          Rip it Up and Start Again  Â£35.02   Five\n",
              "15  Our Band Could Be Your Life: Scenes from the A...  Â£57.25  Three\n",
              "16                                               Olio  Â£23.88    One\n",
              "17  Mesaerion: The Best Science Fiction Stories 18...  Â£37.59    One\n",
              "18                       Libertarianism for Beginners  Â£51.33    Two\n",
              "19                            It's Only the Himalayas  Â£45.17    Two"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71ec5f35-a2c6-420e-8abf-4555b8d90990\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Light in the Attic</td>\n",
              "      <td>Â£51.77</td>\n",
              "      <td>Three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tipping the Velvet</td>\n",
              "      <td>Â£53.74</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Soumission</td>\n",
              "      <td>Â£50.10</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sharp Objects</td>\n",
              "      <td>Â£47.82</td>\n",
              "      <td>Four</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sapiens: A Brief History of Humankind</td>\n",
              "      <td>Â£54.23</td>\n",
              "      <td>Five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The Requiem Red</td>\n",
              "      <td>Â£22.65</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
              "      <td>Â£33.34</td>\n",
              "      <td>Four</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
              "      <td>Â£17.93</td>\n",
              "      <td>Three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
              "      <td>Â£22.60</td>\n",
              "      <td>Four</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The Black Maria</td>\n",
              "      <td>Â£52.15</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
              "      <td>Â£13.99</td>\n",
              "      <td>Two</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Shakespeare's Sonnets</td>\n",
              "      <td>Â£20.66</td>\n",
              "      <td>Four</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Set Me Free</td>\n",
              "      <td>Â£17.46</td>\n",
              "      <td>Five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
              "      <td>Â£52.29</td>\n",
              "      <td>Five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Rip it Up and Start Again</td>\n",
              "      <td>Â£35.02</td>\n",
              "      <td>Five</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
              "      <td>Â£57.25</td>\n",
              "      <td>Three</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Olio</td>\n",
              "      <td>Â£23.88</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
              "      <td>Â£37.59</td>\n",
              "      <td>One</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Libertarianism for Beginners</td>\n",
              "      <td>Â£51.33</td>\n",
              "      <td>Two</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>It's Only the Himalayas</td>\n",
              "      <td>Â£45.17</td>\n",
              "      <td>Two</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71ec5f35-a2c6-420e-8abf-4555b8d90990')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71ec5f35-a2c6-420e-8abf-4555b8d90990 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71ec5f35-a2c6-420e-8abf-4555b8d90990');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86d43af2-95f8-4c17-a24a-a5c9dea0bfdf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86d43af2-95f8-4c17-a24a-a5c9dea0bfdf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86d43af2-95f8-4c17-a24a-a5c9dea0bfdf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"A Light in the Attic\",\n          \"Mesaerion: The Best Science Fiction Stories 1800-1849\",\n          \"Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\\u00c2\\u00a351.77\",\n          \"\\u00c2\\u00a337.59\",\n          \"\\u00c2\\u00a357.25\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"One\",\n          \"Two\",\n          \"Four\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Этап 1: Импорт библиотек ---\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# --- Этап 2: Подготовка к запросу ---\n",
        "\n",
        "# URL страницы, с которой будем работать\n",
        "url = 'https://ru.wikipedia.org/wiki/Python'\n",
        "\n",
        "# Заголовки для имитации запроса от браузера. Это важная часть!\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "}\n",
        "\n",
        "# --- Этап 3: Получение и разбор HTML ---\n",
        "try:\n",
        "    print(f\"Отправляем запрос на: {url}\")\n",
        "    # 1. ВАШ КОД ЗДЕСЬ: Отправьте GET-запрос на 'url' с использованием 'headers'.\n",
        "    #    Результат сохраните в переменную 'response'.\n",
        "    #    Подсказка: используйте requests.get(...)\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    # Эта строка проверит, успешно ли выполнен запрос. Если нет, она вызовет ошибку.\n",
        "    response.raise_for_status()\n",
        "    print(\"Ответ от сервера успешно получен!\")\n",
        "\n",
        "    # 2. ВАШ КОД ЗДЕСЬ: Создайте объект BeautifulSoup для парсинга HTML.\n",
        "    #    Передайте ему текст ответа (response.text) и укажите парсер 'lxml'.\n",
        "    #    Результат сохраните в переменную 'soup'.\n",
        "    soup = BeautifulSoup(response.text, 'lxml')\n",
        "\n",
        "    # --- Этап 4: Поиск нужных элементов ---\n",
        "\n",
        "    # 3. ВАШ КОД ЗДЕСЬ: Найдите ВСЕ теги 'table', у которых атрибут class равен 'wikitable'.\n",
        "    #    Результат (список найденных таблиц) сохраните в переменную 'wikitables'.\n",
        "    #    Подсказка: используйте метод soup.find_all(...) и параметр class_ (с нижним подчеркиванием!).\n",
        "    wikitables = soup.find_all('table', class_='wikitable')\n",
        "\n",
        "    print(f\"Найдено таблиц с классом 'wikitable': {len(wikitables)}\")\n",
        "\n",
        "    # --- Этап 5: Обработка и вывод результатов ---\n",
        "    if not wikitables:\n",
        "        print(\"Таблицы не найдены. Проверьте правильность тега и класса.\")\n",
        "    else:\n",
        "        # Проходим циклом по списку найденных HTML-таблиц\n",
        "        for i, table in enumerate(wikitables):\n",
        "\n",
        "            # 4. ВАШ КОД ЗДЕСЬ: Преобразуйте HTML-код таблицы в DataFrame.\n",
        "            #    Подсказка: используйте pd.read_html(). Ей нужно передать таблицу в виде строки (str(table)).\n",
        "            #    Помните, что pd.read_html() всегда возвращает СПИСОК, поэтому возьмите первый элемент [0].\n",
        "            df = pd.read_html(str(table))[0]\n",
        "\n",
        "            # Выводим результат\n",
        "            print(f\"\\n---------- Таблица №{i+1} ----------\")\n",
        "            print(df.head()) # .head() выведет только первые 5 строк для краткости\n",
        "\n",
        "# --- Этап 6: Обработка ошибок ---\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Ошибка! Не удалось получить страницу. Причина: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Произошла непредвиденная ошибка: {e}\")"
      ],
      "metadata": {
        "id": "SLqZjPdxY8gf",
        "outputId": "9a19eac8-e5ba-496b-aae8-25c2fd062cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отправляем запрос на: https://ru.wikipedia.org/wiki/Python\n",
            "Ответ от сервера успешно получен!\n",
            "Найдено таблиц с классом 'wikitable': 2\n",
            "\n",
            "---------- Таблица №1 ----------\n",
            "         Тип  Изменяемость                                           Описание  \\\n",
            "0       bool  Неизменяемый                                     Логический тип   \n",
            "1  bytearray    Изменяемый                                      Массив байтов   \n",
            "2      bytes  Неизменяемый                                      Массив байтов   \n",
            "3    complex  Неизменяемый                                  Комплексное число   \n",
            "4       dict    Изменяемый  Словарь (ассоциативный массив), представляет с...   \n",
            "\n",
            "                                             Примеры  \n",
            "0                                         True False  \n",
            "1  bytearray(b'Some ASCII') bytearray(b\"Some ASCI...  \n",
            "2  b'Some ASCII' b\"Some ASCII\" bytes([119, 105, 1...  \n",
            "3                                             3+2.7j  \n",
            "4                         {'key1': 1.0, 3: False} {}  \n",
            "\n",
            "---------- Таблица №2 ----------\n",
            "                                             C++[94]  \\\n",
            "0  #include <iostream> int main() {  std::cout <<...   \n",
            "\n",
            "                                            Java[94]              Python[94]  \n",
            "0  public class HelloClass {  public static void ...  print(\"Hello, world!\")  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-946734382.py:52: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(table))[0]\n",
            "/tmp/ipython-input-946734382.py:52: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(str(table))[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "SmYV2Vwj7hIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selenium"
      ],
      "metadata": {
        "id": "OvMnn8-LmPtw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Настройка selenium"
      ],
      "metadata": {
        "id": "9RER97g1NSEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Устанавливаем библиотеку selenium для управления браузером\n",
        "!pip install selenium\n",
        "\n",
        "# Устанавливаем браузер chromium и его драйвер\n",
        "# Опция -y автоматически отвечает \"yes\" на все запросы в процессе установки\n",
        "!apt-get update\n",
        "!apt-get install -y chromium-browser chromium-chromedriver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QeB-ElFkbM6p",
        "outputId": "6a1187a6-525b-46de-90e6-b8acfc883a6b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.37.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
            "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.37.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.37.0 trio-0.31.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:2 https://cli.github.com/packages stable InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,372 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,812 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,988 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,778 kB]\n",
            "Fetched 25.3 MB in 3s (7,279 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor libfuse3-3 libudev1 snapd squashfs-tools systemd-hwe-hwdb udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 snapd\n",
            "  squashfs-tools systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 8 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 34.2 MB of archives.\n",
            "After this operation, 134 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.4 [598 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.17 [76.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.17 [1,557 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.71+ubuntu22.04 [31.6 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.6 [3,668 B]\n",
            "Fetched 34.2 MB in 2s (17.1 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.4_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.17_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.17) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.17) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 126875 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.17_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.17) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.71+ubuntu22.04_amd64.deb ...\n",
            "Unpacking snapd (2.71+ubuntu22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.4) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.17) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.71+ubuntu22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 127105 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.6_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.6) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.6) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.17) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Импортируем необходимые классы из selenium\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "# --- Настройка опций для Chrome ---\n",
        "# Создаем объект опций\n",
        "chrome_options = Options()\n",
        "\n",
        "# Эти опции КРАЙНЕ ВАЖНЫ для работы в Google Colab\n",
        "# 1. '--headless' — запускает браузер без графического интерфейса.\n",
        "chrome_options.add_argument('--headless')\n",
        "\n",
        "# 2. '--no-sandbox' — отключает \"песочницу\", что часто требуется для запуска в Docker-контейнерах, как в Colab.\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "\n",
        "# 3. '--disable-dev-shm-usage' — предотвращает проблемы с нехваткой памяти в некоторых окружениях.\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "print(\"Опции для запуска Chrome успешно настроены.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvB_cLsgbO3o",
        "outputId": "1986462f-dc96-4bf7-878f-1ccede78666b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Опции для запуска Chrome успешно настроены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "# --- Инициализация веб-драйвера ---\n",
        "# Создаем экземпляр драйвера Chrome, передавая ему наши настроенные опции\n",
        "# Selenium автоматически найдет chromedriver, установленный на предыдущем шаге\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "print(\"Веб-драйвер успешно запущен!\")\n",
        "\n",
        "# --- Выполнение задачи ---\n",
        "url = 'https://ru.wikipedia.org/wiki/Python'\n",
        "\n",
        "print(f\"Переходим на страницу: {url}\")\n",
        "# Открываем страницу в виртуальном браузере\n",
        "driver.get(url)\n",
        "\n",
        "# Даем странице пару секунд на полную прогрузку (хорошая практика)\n",
        "time.sleep(2)\n",
        "\n",
        "try:\n",
        "    # Находим элемент по его ID. Заголовок статьи в Википедии имеет id='firstHeading'\n",
        "    # By.ID — это стратегия поиска, указывающая, что мы ищем по идентификатору.\n",
        "    header_element = driver.find_element(By.ID, 'firstHeading')\n",
        "\n",
        "    # Получаем текстовое содержимое найденного элемента\n",
        "    header_text = header_element.text\n",
        "\n",
        "    print(\"\\n--- Результат ---\")\n",
        "    print(f\"Заголовок страницы: '{header_text}'\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Не удалось найти элемент. Ошибка: {e}\")\n",
        "\n",
        "finally:\n",
        "    # --- Завершение работы ---\n",
        "    # КРАЙНЕ ВАЖНО закрыть драйвер, чтобы освободить ресурсы\n",
        "    driver.quit()\n",
        "    print(\"\\nРабота драйвера завершена, ресурсы освобождены.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoi5X4jXbjjl",
        "outputId": "001f2e61-74e0-4ff0-c685-e137768e4be1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Веб-драйвер успешно запущен!\n",
            "Переходим на страницу: https://ru.wikipedia.org/wiki/Python\n",
            "\n",
            "--- Результат ---\n",
            "Заголовок страницы: 'Python'\n",
            "\n",
            "Работа драйвера завершена, ресурсы освобождены.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "import time\n",
        "\n",
        "def setup_driver():\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument(\"--headless\")  # запуск без графического интерфейса\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    # путь к драйверу можно не указывать, если chromedriver уже в PATH\n",
        "    driver = webdriver.Chrome(options=chrome_options)\n",
        "    return driver\n",
        "\n",
        "# --- ЗАПУСК ДРАЙВЕРА ---\n",
        "driver = setup_driver()\n",
        "\n",
        "try:\n",
        "    # --- ШАГ 1: Открытие страницы ---\n",
        "    url = \"https://ru.wikipedia.org/wiki/Python\"\n",
        "    driver.get(url)\n",
        "    print(f\"Успешно перешел на страницу: {url}\")\n",
        "\n",
        "    # --- ШАГ 2: Принятие cookie (если баннер есть) ---\n",
        "    try:\n",
        "        cookie_wait = WebDriverWait(driver, 5)\n",
        "        accept_button = cookie_wait.until(\n",
        "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button#mw-cookie-accept\"))\n",
        "        )\n",
        "        accept_button.click()\n",
        "        print(\"Баннер о cookie принят.\")\n",
        "        time.sleep(1)\n",
        "    except Exception:\n",
        "        print(\"Баннер о cookie не найден, продолжаю выполнение.\")\n",
        "\n",
        "    # --- ШАГ 3: Ожидание загрузки таблиц ---\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "    wait.until(\n",
        "        EC.presence_of_element_located((By.CSS_SELECTOR, \"table.wikitable\"))\n",
        "    )\n",
        "    print(\"Таблицы с классом 'wikitable' загружены!\")\n",
        "\n",
        "    # --- ШАГ 4: Получаем все таблицы ---\n",
        "    tables = driver.find_elements(By.CSS_SELECTOR, \"table.wikitable\")\n",
        "    print(f\"Найдено таблиц: {len(tables)}\")\n",
        "\n",
        "    # --- ШАГ 5: Обработка таблиц через pandas ---\n",
        "    for i, table in enumerate(tables):\n",
        "        html = table.get_attribute(\"outerHTML\")  # получаем HTML таблицы\n",
        "        df = pd.read_html(html)[0]  # преобразуем в DataFrame\n",
        "        print(f\"\\n--- Таблица №{i+1} ---\")\n",
        "        print(df.head())  # выводим первые 5 строк\n",
        "\n",
        "    # --- ШАГ 6: Скриншот страницы ---\n",
        "    driver.save_screenshot(\"wikipedia_python.png\")\n",
        "    print(\"Скриншот 'wikipedia_python.png' сохранен!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Произошла ошибка: {e}\")\n",
        "    driver.save_screenshot(\"wikipedia_error.png\")\n",
        "    print(\"Скриншот 'wikipedia_error.png' сохранен для анализа ошибки.\")\n",
        "\n",
        "finally:\n",
        "    driver.quit()\n",
        "    print(\"\\nРабота драйвера завершена.\")"
      ],
      "metadata": {
        "id": "5pWFheblgDjh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0b4304-7240-4ccb-f700-b6b3661a76f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Успешно перешел на страницу: https://ru.wikipedia.org/wiki/Python\n",
            "Баннер о cookie не найден, продолжаю выполнение.\n",
            "Таблицы с классом 'wikitable' загружены!\n",
            "Найдено таблиц: 2\n",
            "\n",
            "--- Таблица №1 ---\n",
            "         Тип  Изменяемость                                           Описание  \\\n",
            "0       bool  Неизменяемый                                     Логический тип   \n",
            "1  bytearray    Изменяемый                                      Массив байтов   \n",
            "2      bytes  Неизменяемый                                      Массив байтов   \n",
            "3    complex  Неизменяемый                                  Комплексное число   \n",
            "4       dict    Изменяемый  Словарь (ассоциативный массив), представляет с...   \n",
            "\n",
            "                                             Примеры  \n",
            "0                                         True False  \n",
            "1  bytearray(b'Some ASCII') bytearray(b\"Some ASCI...  \n",
            "2  b'Some ASCII' b\"Some ASCII\" bytes([119, 105, 1...  \n",
            "3                                             3+2.7j  \n",
            "4                         {'key1': 1.0, 3: False} {}  \n",
            "\n",
            "--- Таблица №2 ---\n",
            "                                             C++[94]  \\\n",
            "0  #include <iostream> int main() {  std::cout <<...   \n",
            "\n",
            "                                            Java[94]              Python[94]  \n",
            "0  public class HelloClass {  public static void ...  print(\"Hello, world!\")  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1612038090.py:54: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(html)[0]  # преобразуем в DataFrame\n",
            "/tmp/ipython-input-1612038090.py:54: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  df = pd.read_html(html)[0]  # преобразуем в DataFrame\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Скриншот 'wikipedia_python.png' сохранен!\n",
            "\n",
            "Работа драйвера завершена.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Контрольные вопросы по библиотекам для парсинга**\n",
        "\n",
        "#### **Блок 1: Библиотека `requests` (\"Курьер\")**\n",
        "\n",
        "Эти вопросы проверяют ваше умение получать данные с сервера.\n",
        "\n",
        "1.  **Фундаментальный вопрос:** В чем основная задача библиотеки `requests`? Что она делает, а чего, наоборот, делать **не умеет** (например, в контексте JavaScript)?\n",
        "2.  **Типы запросов:** В чем принципиальная разница между `GET` и `POST` запросами? В какой из наших лабораторных задач мы использовали `POST` и для какой цели?\n",
        "3.  **Объект ответа:** Вы выполнили команду `response = requests.get(url)`. Какие три важнейших атрибута объекта `response` вы будете использовать и для чего каждый из них предназначен (`status_code`, `text`, `content`)?\n",
        "4.  **Обработка ошибок:** Почему проверка `response.status_code == 200` является обязательным шагом в любом надежном парсере? Что означает код `404`? А код `403`?\n",
        "5.  **Работа с API:** Почему для получения данных от API (как в задаче с GitHub) мы использовали метод `response.json()`, а не просто брали `response.text`? В чем преимущество такого подхода?\n",
        "6.  **Сессии:** Объясните своими словами, что такое `requests.Session()`. Какую проблему решает объект сессии, и почему без него не удалось бы выполнить задачу с авторизацией на сайте?\n",
        "7.  **Параметры запроса:** Как с помощью `requests` передать в URL GET-параметры (например, `?sort=date&page=2`) без ручного формирования строки URL? Какой аргумент функции `get()` для этого используется?\n",
        "\n",
        "---\n",
        "\n",
        "#### **Блок 2: Библиотека `BeautifulSoup` (\"Навигатор\")**\n",
        "\n",
        "Эти вопросы проверяют ваше умение разбирать HTML-код и находить в нем нужные данные.\n",
        "\n",
        "8.  **Основное назначение:** Какую проблему решает `BeautifulSoup`? Что она принимает на вход и что отдает на выходе?\n",
        "9.  **Ключевое различие:** В чем фундаментальная разница между методами `.find()` и `.find_all()`? Приведите пример, когда нужно использовать один, а когда — другой.\n",
        "10. **Синтаксис поиска:** Как найти тег `<p>` с CSS-классом `price_color`? Почему в коде мы пишем `class_` с нижним подчеркиванием, а не просто `class`?\n",
        "11. **Извлечение данных:** У вас есть объект тега, сохраненный в переменной `tag`. Как из него извлечь:\n",
        "    *   Весь видимый текст внутри него?\n",
        "    *   Значение атрибута `href`?\n",
        "12. **Вложенный поиск:** Ваш парсер нашел общий контейнер товара (`<div class=\"product\">`). Как продолжить поиск и найти цену, которая находится **внутри** этого контейнера? Напишите примерный код.\n",
        "13. **Продвинутая навигация:** Представьте, что вы нашли заголовок `<h2>Описание</h2>`. Само описание находится в следующем за ним теге `<p>`. Какой метод `BeautifulSoup` позволит вам найти этот \"соседний\" тег, не начиная поиск заново от корня документа?\n",
        "14. **Очистка данных:** Почему простого извлечения `.text` часто недостаточно для реальных задач? Какие две стандартные операции по очистке текста вы применяли в лабораторных работах?\n",
        "\n",
        "---\n",
        "\n",
        "#### **Блок 3: Библиотека `Selenium` (\"Робот-пользователь\")**\n",
        "\n",
        "Эти вопросы проверяют ваше понимание работы с динамическими сайтами и автоматизацией браузера.\n",
        "\n",
        "15. **Главный вопрос:** Назовите основную причину, по которой мы вынуждены использовать `Selenium`, а не `requests`. Какую технологию `Selenium` умеет обрабатывать, а `requests` — нет?\n",
        "16. **Проблема синхронизации:** Почему использование `time.sleep()` для ожидания загрузки элементов на странице является плохой практикой? Каков правильный, надежный способ дождаться появления элемента?\n",
        "17. **Явные ожидания (Explicit Waits):** Объясните своими словами, что делают эти три строки кода:\n",
        "    ```python\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "    element = wait.until(\n",
        "        EC.presence_of_element_located((By.CLASS_NAME, 'price'))\n",
        "    )\n",
        "    ```\n",
        "18. **Взаимодействие с формами:** Опишите последовательность из трех основных действий, которые нужно совершить с помощью `Selenium`, чтобы ввести текст в поле поиска и нажать на кнопку.\n",
        "19. **Исполнение JavaScript:** Для чего в задаче с \"бесконечным свитком\" мы использовали команду `driver.execute_script()`? Можно ли было добиться того же результата другим методом `Selenium`?\n",
        "20. **Интеграция библиотек:** В какой момент работы парсера на `Selenium` имеет смысл передать управление библиотеке `BeautifulSoup`? Что для этого нужно получить от `driver` и как это сделать?\n",
        "21. **Завершение работы:** Почему команда `driver.quit()` является обязательной в конце скрипта? Что произойдет, если ее не вызывать?\n",
        "\n",
        "---\n",
        "\n",
        "#### **Блок 4: Синтез и сценарии (Проверка общего понимания)**\n",
        "\n",
        "22. **Выбор инструмента:** Вам нужно спарсить три сайта:\n",
        "    *   А) Таблицу курсов валют со страницы Центробанка.\n",
        "    *   Б) Ленту комментариев на YouTube, которая подгружается при прокрутке.\n",
        "    *   В) Данные о погоде с публичного погодного API.\n",
        "    Какой основной инструмент (`requests`, `bs4`, `Selenium`) вы выберете для **каждой** из этих задач и почему?\n",
        "\n",
        "23. **Отладка:** Ваш парсер на `BeautifulSoup` вчера работал, а сегодня перестал, выдавая ошибку `AttributeError: 'NoneType' object has no attribute 'text'`. Назовите самую вероятную причину этой проблемы. Каков ваш первый шаг для диагностики?\n",
        "\n",
        "24. **Этика парсинга:** Что такое файл `robots.txt` на сайте и почему его рекомендуется проверять перед запуском массового сбора данных?"
      ],
      "metadata": {
        "id": "MorSgT4YmN_A"
      }
    }
  ]
}